{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Working with Tensorflow and Core Learning Algorithms.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "oixCgcYYH5bb",
    "hRbfSFExURZM",
    "XrOHRGILUcAZ",
    "KMZ9SRQE38te",
    "Ag1dTns48uMc"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKcq7_ZqB7LI",
    "colab_type": "text"
   },
   "source": [
    "# Hey Everyone! Here's my progress in learning Tensorflow and practicing Machine Learning. **Part 1**\n",
    "\n",
    "\n",
    "**Follow my journey on social media:** [Podcast](https://open.spotify.com/show/6FxUBKO4bqwRWsjAIGZMwz) | [Twitter](https://twitter.com/tlkdata2me) | [Instagram](https://www.instagram.com/tlkdata2me/) | [LinkedIn](https://www.linkedin.com/in/shecananalyze/) \n",
    "\n",
    "Learning Source: [Click here to take freeCodeCamp's TensorFlow 2.0 Complete Course](https://www.youtube.com/watch?v=tPYj3fFJGjk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oixCgcYYH5bb",
    "colab_type": "text"
   },
   "source": [
    "# Intro to Tensorflow\n",
    "Vector - A **tensor** is a **vector** of a number (n) of dimensions that represent all types of data which are represented in *shapes.*\n",
    "\n",
    "Shapes - The dimension of the data being represented. (EX 2 rows 2 Columns)\n",
    "\n",
    "**Graphs and Sessions**\n",
    "- Graph - Set of computations that take place one after the other\n",
    "- Session - At this point I believe sessions are components from the graph (I will update this upon understanding)\n",
    "\n",
    "**Types of Tensors**\n",
    "- Variable - Right now I understand that variables can't be changed. (Immutable) "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ax4VjKJGE7DO",
    "colab_type": "code",
    "outputId": "98823470-dc8d-408f-90ea-3c8d165ffc2b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "print(tf.version)"
   ],
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow._api.v2.version' from '/opt/homebrew/Caskroom/miniforge/base/envs/tf/lib/python3.9/site-packages/tensorflow/_api/v2/version/__init__.py'>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iwGmGpEQMipe",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Video Example (We Do)\n",
    "#Here I created a tensor of 0's with the shape of 5 sets of 5 arrays 5 rows with 5 columns\n",
    "t = tf.zeros([5,5,5,5]) \n",
    "#print(t)\n",
    "#Reshapes the tensor with 625 elements (elements are the number 0 in this case)\n",
    "t = tf.reshape(t,[625]) \n",
    "#print(t)\n",
    "#Reshapes the tensor with 125 rows (using -1 will create the amoun of columns needed to complete the task)\n",
    "t = tf.reshape(t,[125, -1]) \n",
    "#print(t)"
   ],
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IFYJPXPBNKdl",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# My Check on Learning (I Do)\n",
    "c = tf.zeros([2, 3, 4, 5])\n",
    "#print(c)\n",
    "c = tf.reshape(c, [5, 4, 3, 2])\n",
    "#print(c)\n",
    "# Or\n",
    "c = tf.reshape(c, [15, -1])\n",
    "#print(c)"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRbfSFExURZM",
    "colab_type": "text"
   },
   "source": [
    "# Core Learning Algoriths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrOHRGILUcAZ",
    "colab_type": "text"
   },
   "source": [
    "##  Linear Regression\n",
    "- Linear Regression - When data points are related linearly, we can use the given points to create a line of best fit and predict future values."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7-7uU3waYDIP",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from IPython.display import clear_output, display\n",
    "from six.moves import urllib\n",
    "\n",
    "import tensorflow as tf "
   ],
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cHkJQppfwrx",
    "colab_type": "text"
   },
   "source": [
    "Using the Titanic data set from Kaggle to predict the survival of passengers on the Titanic\n",
    "\n",
    "Steps to take when building a model\n",
    "\n",
    "1. Load the data\n",
    "2. Explore the data\n",
    "3. Catagorize the data\n",
    "4. Create feature columns for the data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WLN8k7dRYlTV",
    "colab_type": "code",
    "outputId": "8ca0ed40-348e-4ac3-9782-846f16609e32",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# Load dataset.\n",
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data\n",
    "display(dftrain.head())\n",
    "y_train = dftrain.pop('survived') #pop removes a column of information and saves it for later under the given variable name\n",
    "y_eval = dfeval.pop('survived')\n",
    "display(dftrain.head())"
   ],
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n0         0    male  22.0                   1      0   7.2500  Third  unknown   \n1         1  female  38.0                   1      0  71.2833  First        C   \n2         1  female  26.0                   0      0   7.9250  Third  unknown   \n3         1  female  35.0                   1      0  53.1000  First        C   \n4         0    male  28.0                   0      0   8.4583  Third  unknown   \n\n   embark_town alone  \n0  Southampton     n  \n1    Cherbourg     n  \n2  Southampton     y  \n3  Southampton     n  \n4   Queenstown     y  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>survived</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>n_siblings_spouses</th>\n      <th>parch</th>\n      <th>fare</th>\n      <th>class</th>\n      <th>deck</th>\n      <th>embark_town</th>\n      <th>alone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>Third</td>\n      <td>unknown</td>\n      <td>Southampton</td>\n      <td>n</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>First</td>\n      <td>C</td>\n      <td>Cherbourg</td>\n      <td>n</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>Third</td>\n      <td>unknown</td>\n      <td>Southampton</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>First</td>\n      <td>C</td>\n      <td>Southampton</td>\n      <td>n</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>male</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.4583</td>\n      <td>Third</td>\n      <td>unknown</td>\n      <td>Queenstown</td>\n      <td>y</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n0    male  22.0                   1      0   7.2500  Third  unknown   \n1  female  38.0                   1      0  71.2833  First        C   \n2  female  26.0                   0      0   7.9250  Third  unknown   \n3  female  35.0                   1      0  53.1000  First        C   \n4    male  28.0                   0      0   8.4583  Third  unknown   \n\n   embark_town alone  \n0  Southampton     n  \n1    Cherbourg     n  \n2  Southampton     y  \n3  Southampton     n  \n4   Queenstown     y  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sex</th>\n      <th>age</th>\n      <th>n_siblings_spouses</th>\n      <th>parch</th>\n      <th>fare</th>\n      <th>class</th>\n      <th>deck</th>\n      <th>embark_town</th>\n      <th>alone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>Third</td>\n      <td>unknown</td>\n      <td>Southampton</td>\n      <td>n</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>First</td>\n      <td>C</td>\n      <td>Cherbourg</td>\n      <td>n</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>Third</td>\n      <td>unknown</td>\n      <td>Southampton</td>\n      <td>y</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>First</td>\n      <td>C</td>\n      <td>Southampton</td>\n      <td>n</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>male</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.4583</td>\n      <td>Third</td>\n      <td>unknown</td>\n      <td>Queenstown</td>\n      <td>y</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NvKHmQEsbDU7",
    "colab_type": "code",
    "outputId": "e2df923f-0983-46f0-fb03-646fe7a0ef16",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "#Explore the data\n",
    "dftrain.describe() #Gives overall information on data set"
   ],
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "              age  n_siblings_spouses       parch        fare\ncount  627.000000          627.000000  627.000000  627.000000\nmean    29.631308            0.545455    0.379585   34.385399\nstd     12.511818            1.151090    0.792999   54.597730\nmin      0.750000            0.000000    0.000000    0.000000\n25%     23.000000            0.000000    0.000000    7.895800\n50%     28.000000            0.000000    0.000000   15.045800\n75%     35.000000            1.000000    0.000000   31.387500\nmax     80.000000            8.000000    5.000000  512.329200",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>n_siblings_spouses</th>\n      <th>parch</th>\n      <th>fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>627.000000</td>\n      <td>627.000000</td>\n      <td>627.000000</td>\n      <td>627.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>29.631308</td>\n      <td>0.545455</td>\n      <td>0.379585</td>\n      <td>34.385399</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>12.511818</td>\n      <td>1.151090</td>\n      <td>0.792999</td>\n      <td>54.597730</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.750000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>23.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.895800</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>15.045800</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>35.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>31.387500</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>5.000000</td>\n      <td>512.329200</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4dVwpY6EcTm8",
    "colab_type": "code",
    "outputId": "72ddc2f0-9fcd-4886-ed65-bfcdbb5e861c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "dftrain.shape #Shape of data"
   ],
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "(627, 9)"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TkA-dBIPctp8",
    "colab_type": "code",
    "outputId": "61bddeaf-7a26-41c5-9223-4e330174e507",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "dftrain.age.hist(bins=20) #bins-increments of graphing"
   ],
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Bj8dtRtHdBhB",
    "colab_type": "code",
    "outputId": "05378d9e-e76b-41ba-c81b-0b0d72d377f4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "dftrain.sex.value_counts().plot(kind='barh')"
   ],
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HfcT-YsEdU-B",
    "colab_type": "code",
    "outputId": "da31872a-eb68-4d94-97b5-bb82be8bdeff",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "dftrain['class'].value_counts().plot(kind='barh')"
   ],
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kFfwi2mAdZCf",
    "colab_type": "code",
    "outputId": "dcc62094-f79f-4e1f-d3b2-27e2a98dca79",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "pd.concat([dftrain, y_train], axis=1).groupby('sex').survived.mean().plot(kind='barh').set_xlabel('% survive')"
   ],
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 0, '% survive')"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVyZQf4Seitd",
    "colab_type": "text"
   },
   "source": [
    "- Most passengers are in their 20's or 30's\n",
    "- Most passengers are male\n",
    "- Most passengers are in \"Third\" class\n",
    "- Females have a much higher chance of survival"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Training vs Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYGmfiw2e1aj",
    "colab_type": "text"
   },
   "source": [
    "**Training data** is what we feed to the model so that it can develop and learn.\n",
    "\n",
    "**Testing data** is what we use to evaulate the model and see how well it is performing. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pwzKVjxzdcD4",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Categorize the data"
   ],
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywzanI1Sgf7k",
    "colab_type": "text"
   },
   "source": [
    "**Categorical data** - non-numerical data that can be placed under a specified field\n",
    "- Note: Categorical data can be represented by numbers to identify the categories they belong to. (ex: Male = 1, Female = 0)\n",
    "\n",
    "**Numerical data** - data that's represented by numbers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jF87tkcwe-mw",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
    "                       'embark_town', 'alone']\n",
    "NUMERIC_COLUMNS = ['age', 'fare']"
   ],
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_orfKwlhh0Mn",
    "colab_type": "code",
    "outputId": "e978ab8d-5be9-4ac1-abd6-ff262d53cba7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "dftrain['class'].unique() #.unique() gives all of the unique values withing the dataset (the names of the different data elements)"
   ],
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Third', 'First', 'Second'], dtype=object)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nesKdX_MhfWm",
    "colab_type": "code",
    "outputId": "145a0597-a6ab-4b46-acb5-c296a6c11ea7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "feature_columns = []\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "  vocabulary = dftrain[feature_name].unique()  # gets a list of all unique values from given feature column\n",
    "  #Create a column of feature names with the different associated vocabulary terms\n",
    "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "\n",
    "print(feature_columns)"
   ],
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyDLCCiM5MP0",
    "colab_type": "text"
   },
   "source": [
    "### Training process\n",
    "*  Models must be fed the data in batches\n",
    "* Batches are fed according to Epochs \n",
    "  * Epochs are how many times the model will see the same data. Feeding the data to the model in variations\n",
    "  Note: Over feeding the model can harm the outcome so feed it a little at a time.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhNNjHM75s6y",
    "colab_type": "text"
   },
   "source": [
    "### Input Function for Linear Regression\n",
    "The TensorFlow model we are going to use requires that the data we pass it comes in as a tf.data.Dataset object. This means we must create a **input function** that can **convert** our current **pandas dataframe into that object.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Gbf4QkyQjUOr",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "  def input_function():  # inner function, this will be returned\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(1000)  # randomize order of data\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n",
    "    return ds  # return a batch of the dataset\n",
    "  return input_function  # return a function object for use\n",
    "\n",
    "train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False) #num_epochs is 1 because we aren't training this dataset like the line above. Shuffle is False because we don't need to shuffle since we are testing it."
   ],
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHXKA0Uh6Qq6",
    "colab_type": "text"
   },
   "source": [
    "### Creating the Linear Regression Model\n",
    "\n",
    "Here we will use a **linear estimator** utilize the linear regression algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "U11rchVf51L3",
    "colab_type": "code",
    "outputId": "700b4ec7-0159-4c04-8a3b-485e0ea36acd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "# We create a linear estimtor by passing the feature columns we created earlier through an estimator module\n",
    "\n",
    "linear_est.train(train_input_fn)  # train\n",
    "result = linear_est.evaluate(eval_input_fn)  # get model metrics/stats by testing data\n",
    "\n",
    "clear_output()  # clears console output\n",
    "print(result['accuracy'])  # the result variable is simply a dict of stats about our model that tells the accuracy of it\n",
    "#Accuracy - compares the dataset results with models predicted results to get the accuracy of the data\n",
    "print(result)"
   ],
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7462121\n",
      "{'accuracy': 0.7462121, 'accuracy_baseline': 0.625, 'auc': 0.8284664, 'auc_precision_recall': 0.7863024, 'average_loss': 0.50324637, 'label/mean': 0.375, 'loss': 0.49832425, 'precision': 0.63559324, 'prediction/mean': 0.45881948, 'recall': 0.75757575, 'global_step': 200}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyXwWCwp7yHY",
    "colab_type": "text"
   },
   "source": [
    "### Predicting the data set with the model\n",
    "\n",
    "How to make predictions for every point in the evaluation data set\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Q2UcXp5b7QqX",
    "colab_type": "code",
    "outputId": "ca85a1ea-c75c-4ace-95f2-1cc1fbbeb404",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "#Check the predictions of the model\n",
    "#Here we will turn the results into a list to get a dictionary of all points and predictions\n",
    "result = list(linear_est.predict(eval_input_fn))\n",
    "#print(result[0])\n",
    "#Here are looking for the 'probabilities' dict because it will help us to see the probability that someone will survive or won't survive\n",
    "#Look for this --> {'probabilities': array([0.9108078 (<--won't survive(0)) , 0.08919217 (<-- will survive(1))]}\n",
    "\n",
    "#Here we will print the probability of survival (1)\n",
    "print(result[0]['probabilities'][0]) #Format: [passenger/data point][data set dict][outcome (survival)]"
   ],
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/pf/pd8w_0hd4jlcz3k9x4kctdhh0000gn/T/tmpwbo441iw/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 07:48:23.855140: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-11 07:48:23.855159: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-03-11 07:48:23.869957: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:48:23.878445: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:48:23.886504: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:48:23.896878: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:48:23.904358: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:48:23.912032: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8795546\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkqMOJpV1W8E",
    "colab_type": "text"
   },
   "source": [
    "To put this together we can evaluate the passengers' attributes to see if the prediction makes sense with the dfeval.loc[ ] method  "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6mjZmP1lxkiM",
    "colab_type": "code",
    "outputId": "3a13b463-9c77-4088-b60e-0c4a40f903c6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "print(dfeval.loc[36])\n",
    "print(y_eval.loc[36])\n",
    "print(result[36]['probabilities'][1]) \n",
    "#This will give us the passengers details and their chance of survival and if they survived"
   ],
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                          male\n",
      "age                          36.5\n",
      "n_siblings_spouses              0\n",
      "parch                           2\n",
      "fare                         26.0\n",
      "class                      Second\n",
      "deck                            F\n",
      "embark_town           Southampton\n",
      "alone                           n\n",
      "Name: 36, dtype: object\n",
      "0\n",
      "0.281665\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMZ9SRQE38te",
    "colab_type": "text"
   },
   "source": [
    "##  Classification\n",
    "Differentiating data points and separating them into classes. Predicting the probability that the data point is in specified classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op51fZxt5Sur",
    "colab_type": "text"
   },
   "source": [
    "### Dataset\n",
    "This specific dataset seperates flowers into 3 different classes of species.\n",
    "\n",
    "* Setosa\n",
    "* Versicolor\n",
    "* Virginica\n",
    "\n",
    "The information about each flower is the following.\n",
    "\n",
    "* sepal length\n",
    "* sepal width\n",
    "* petal length\n",
    "* petal width"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gkl1Ccip5R3z",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "# Lets define some constants to help us later on"
   ],
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "arIFAw7U2Hcf",
    "colab_type": "code",
    "outputId": "cc66e61e-0ad1-4a50-91ce-23650b4cd350",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    }
   },
   "source": [
    "#Call in the data set\n",
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "# Here we use keras (a module inside of TensorFlow) to grab our datasets and read them into a pandas dataframe"
   ],
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eemrOkOl6DRP",
    "colab_type": "code",
    "outputId": "d429c7fe-8f21-4f96-a047-f500bcbe14c3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    }
   },
   "source": [
    "train.head()"
   ],
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n0          6.4         2.8          5.6         2.2        2\n1          5.0         2.3          3.3         1.0        1\n2          4.9         2.5          4.5         1.7        2\n3          4.9         3.1          1.5         0.1        0\n4          5.7         3.8          1.7         0.3        0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SepalLength</th>\n      <th>SepalWidth</th>\n      <th>PetalLength</th>\n      <th>PetalWidth</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6.4</td>\n      <td>2.8</td>\n      <td>5.6</td>\n      <td>2.2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>2.3</td>\n      <td>3.3</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.9</td>\n      <td>2.5</td>\n      <td>4.5</td>\n      <td>1.7</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.9</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.7</td>\n      <td>3.8</td>\n      <td>1.7</td>\n      <td>0.3</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_lU-guKU6QRC",
    "colab_type": "code",
    "outputId": "fdfb7039-d022-4fdb-877f-993eeddce141",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    }
   },
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "train.head() # the species column is now gone"
   ],
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "   SepalLength  SepalWidth  PetalLength  PetalWidth\n0          6.4         2.8          5.6         2.2\n1          5.0         2.3          3.3         1.0\n2          4.9         2.5          4.5         1.7\n3          4.9         3.1          1.5         0.1\n4          5.7         3.8          1.7         0.3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SepalLength</th>\n      <th>SepalWidth</th>\n      <th>PetalLength</th>\n      <th>PetalWidth</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6.4</td>\n      <td>2.8</td>\n      <td>5.6</td>\n      <td>2.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>2.3</td>\n      <td>3.3</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.9</td>\n      <td>2.5</td>\n      <td>4.5</td>\n      <td>1.7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.9</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.7</td>\n      <td>3.8</td>\n      <td>1.7</td>\n      <td>0.3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uPYKsNu66mCT",
    "colab_type": "code",
    "outputId": "2213bd4b-d669-4d09-8c2b-48970e645817",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "train.shape"
   ],
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "(120, 4)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGTDLr_t7uHd",
    "colab_type": "text"
   },
   "source": [
    "### Input Function for Classification"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "q_vQWLXY6rRA",
    "colab_type": "code",
    "outputId": "13935eb7-1ae5-46b1-f28a-398075e49b10",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    }
   },
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffling and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "\n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "# Feature columns describe how to use the input. We don't need the numerical of the previous input function because we're looking for the key values\n",
    "my_feature_columns = []\n",
    "#this code will loop through all of the keys in the dataset\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(my_feature_columns)"
   ],
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ag1dTns48uMc",
    "colab_type": "text"
   },
   "source": [
    "##  Building the Classification Model\n",
    "\n",
    "Here we will use the DNN Classifier (Deep Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c9SDMlkf8J8z",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3)"
   ],
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/pf/pd8w_0hd4jlcz3k9x4kctdhh0000gn/T/tmpwr9w6jim\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/pf/pd8w_0hd4jlcz3k9x4kctdhh0000gn/T/tmpwr9w6jim', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZTW8OsBW-Koh",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#Here we trained the model\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=5000)\n",
    "# We include a lambda to avoid creating an inner function previously"
   ],
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 07:48:24.629489: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-11 07:48:24.629507: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-03-11 07:48:24.637436: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:48:24.658424: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:48:24.666031: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:48:24.668976: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:48:24.675912: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/pf/pd8w_0hd4jlcz3k9x4kctdhh0000gn/T/tmpwr9w6jim/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 07:48:25.097039: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:48:25.240136: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:48:25.246621: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.3685837, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 07:48:25.336990: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 181.166\n",
      "INFO:tensorflow:loss = 1.0383998, step = 100 (0.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.1\n",
      "INFO:tensorflow:loss = 0.97775346, step = 200 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.794\n",
      "INFO:tensorflow:loss = 0.9356633, step = 300 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.211\n",
      "INFO:tensorflow:loss = 0.8727781, step = 400 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.65\n",
      "INFO:tensorflow:loss = 0.82019174, step = 500 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.465\n",
      "INFO:tensorflow:loss = 0.7835121, step = 600 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.964\n",
      "INFO:tensorflow:loss = 0.7488316, step = 700 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.671\n",
      "INFO:tensorflow:loss = 0.72215486, step = 800 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.362\n",
      "INFO:tensorflow:loss = 0.69863653, step = 900 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.579\n",
      "INFO:tensorflow:loss = 0.670974, step = 1000 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.576\n",
      "INFO:tensorflow:loss = 0.6583252, step = 1100 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.872\n",
      "INFO:tensorflow:loss = 0.63326836, step = 1200 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.987\n",
      "INFO:tensorflow:loss = 0.61373913, step = 1300 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.32\n",
      "INFO:tensorflow:loss = 0.60813636, step = 1400 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.509\n",
      "INFO:tensorflow:loss = 0.5906117, step = 1500 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.532\n",
      "INFO:tensorflow:loss = 0.56392896, step = 1600 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.857\n",
      "INFO:tensorflow:loss = 0.5686296, step = 1700 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.042\n",
      "INFO:tensorflow:loss = 0.55134535, step = 1800 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.481\n",
      "INFO:tensorflow:loss = 0.5295853, step = 1900 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.163\n",
      "INFO:tensorflow:loss = 0.5242435, step = 2000 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.467\n",
      "INFO:tensorflow:loss = 0.5210345, step = 2100 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.26\n",
      "INFO:tensorflow:loss = 0.5182067, step = 2200 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.638\n",
      "INFO:tensorflow:loss = 0.50705755, step = 2300 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.552\n",
      "INFO:tensorflow:loss = 0.4977964, step = 2400 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.632\n",
      "INFO:tensorflow:loss = 0.48017, step = 2500 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.309\n",
      "INFO:tensorflow:loss = 0.47311985, step = 2600 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.912\n",
      "INFO:tensorflow:loss = 0.47408706, step = 2700 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.783\n",
      "INFO:tensorflow:loss = 0.47686368, step = 2800 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.576\n",
      "INFO:tensorflow:loss = 0.47105137, step = 2900 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.99\n",
      "INFO:tensorflow:loss = 0.4566695, step = 3000 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.779\n",
      "INFO:tensorflow:loss = 0.45018697, step = 3100 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.788\n",
      "INFO:tensorflow:loss = 0.44694358, step = 3200 (0.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.065\n",
      "INFO:tensorflow:loss = 0.4377451, step = 3300 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.015\n",
      "INFO:tensorflow:loss = 0.42950314, step = 3400 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.445\n",
      "INFO:tensorflow:loss = 0.41613877, step = 3500 (0.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.463\n",
      "INFO:tensorflow:loss = 0.4283976, step = 3600 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.722\n",
      "INFO:tensorflow:loss = 0.42498225, step = 3700 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.51\n",
      "INFO:tensorflow:loss = 0.40937632, step = 3800 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.767\n",
      "INFO:tensorflow:loss = 0.40806976, step = 3900 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.567\n",
      "INFO:tensorflow:loss = 0.40316623, step = 4000 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.557\n",
      "INFO:tensorflow:loss = 0.4091686, step = 4100 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.364\n",
      "INFO:tensorflow:loss = 0.38973832, step = 4200 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.46\n",
      "INFO:tensorflow:loss = 0.3992526, step = 4300 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.539\n",
      "INFO:tensorflow:loss = 0.3941955, step = 4400 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.345\n",
      "INFO:tensorflow:loss = 0.38225433, step = 4500 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.675\n",
      "INFO:tensorflow:loss = 0.38082635, step = 4600 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.842\n",
      "INFO:tensorflow:loss = 0.37686986, step = 4700 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.562\n",
      "INFO:tensorflow:loss = 0.3758125, step = 4800 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.632\n",
      "INFO:tensorflow:loss = 0.37892997, step = 4900 (0.539 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/pf/pd8w_0hd4jlcz3k9x4kctdhh0000gn/T/tmpwr9w6jim/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.3690435.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x136d2f3a0>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "omHaMKYJ_JyD",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#Here we will evaluate the model\n",
    "#We didn't specify the number of steps because during evaluation the model will only look at the testing data one time.\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ],
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-03-11T07:48:50\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/pf/pd8w_0hd4jlcz3k9x4kctdhh0000gn/T/tmpwr9w6jim/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.15302s\n",
      "INFO:tensorflow:Finished evaluation at 2022-03-11-07:48:51\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.9333334, average_loss = 0.43107137, global_step = 5000, loss = 0.43107137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 07:48:50.981543: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-11 07:48:50.981567: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-03-11 07:48:50.991787: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:48:50.998217: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:48:51.004589: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:48:51.011067: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:48:51.018688: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:48:51.023347: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:48:51.086910: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /var/folders/pf/pd8w_0hd4jlcz3k9x4kctdhh0000gn/T/tmpwr9w6jim/model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 0.933\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKBuojugA3cI",
    "colab_type": "text"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uFTAoOYFActO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def input_fn(features, batch_size=256):\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "predict = {}\n",
    "\n",
    "print(\"Please type numeric values as prompted.\")\n",
    "for feature in features:\n",
    "  valid = True\n",
    "  while valid: \n",
    "    val = input(feature + \": \")\n",
    "    if not val.isdigit(): valid = False\n",
    "\n",
    "  predict[feature] = [float(val)]\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
    "for pred_dict in predictions:\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
    "        SPECIES[class_id], 100 * probability))"
   ],
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type numeric values as prompted.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/pf/pd8w_0hd4jlcz3k9x4kctdhh0000gn/T/ipykernel_84058/2720942837.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misdigit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mvalid\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m   \u001B[0mpredict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfeature\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0mpredictions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mclassifier\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_fn\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mlambda\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0minput_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: could not convert string to float: ''"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CWiHaZIlCq2H",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(pred_dict)\n",
    "\n",
    "#Probability percentage tells you how likely the data point is to be classified as the key value predictions.\n",
    "#Class ID tells you what value the prediction is from the original list."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzP2QYFDA0DN",
    "colab_type": "text"
   },
   "source": [
    "##  Clustering\n",
    "\n",
    "**Clustering** is an *unsupervised learning algorithm*. It finds clusters of like data and tells you the location of the clusters. \n",
    "\n",
    "### Basic Algorithm for K-Means.\n",
    "- Step 1: Randomly pick K points to place K centroids\n",
    "  - **Centroids** are the base of a cluster and tells you where the needed cluster is.\n",
    "- Step 2: Assign all the data points to the centroids by distance. The closest centroid to a point is the one it is assigned to.\n",
    "- Step 3: Average all the points belonging to each centroid to find the middle of those clusters (center of mass). Place the corresponding centroids into that position.\n",
    "- Step 4: Reassign every point once again to the closest centroid.\n",
    "- Step 5: Repeat steps 3-4 until no point changes which centroid it belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-f47NKw5JFQ7",
    "colab_type": "text"
   },
   "source": [
    "##  Hidden Markov Models\n",
    "\"The Hidden Markov Model is a finite set of states, each of which is associated with a (generally multidimensional) probability distribution []. Transitions among the states are governed by a set of probabilities called transition probabilities.\" (http://jedlik.phy.bme.hu/~gerjanos/HMM/node4.html)\n",
    "\n",
    "A hidden markov model works with probabilities to predict future events or states. In this section we will learn how to create a hidden markov model that can predict the weather.\n",
    "\n",
    "This section is based on the following TensorFlow tutorial. https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/HiddenMarkovModel\n",
    "\n",
    "### Data\n",
    "Let's start by discussing the type of data we use when we work with a hidden markov model.\n",
    "\n",
    "In the previous sections we worked with large datasets of 100's of different entries. For a markov model we are only interested in probability distributions that have to do with states.\n",
    "\n",
    "We can find these probabilities from large datasets or may already have these values. We'll run through an example in a second that should clear some things up, but let's discuss the components of a markov model.\n",
    "\n",
    "**States**: In each markov model we have a finite set of states. These states could be something like \"warm\" and \"cold\" or \"high\" and \"low\" or even \"red\", \"green\" and \"blue\". These states are \"hidden\" within the model, which means we do not direcly observe them.\n",
    "\n",
    "**Observations**: Each state has a particular outcome or observation associated with it based on a probability distribution. An example of this is the following: On a hot day Tim has a 80% chance of being happy and a 20% chance of being sad.\n",
    "\n",
    "**Transitions**: Each state will have a probability defining the likelyhood of transitioning to a different state. An example is the following: a cold day has a 30% chance of being followed by a hot day and a 70% chance of being follwed by another cold day.\n",
    "\n",
    "To create a hidden markov model we need.\n",
    "\n",
    "- States\n",
    "- Observation Distribution\n",
    "- Transition Distribution\n",
    "\n",
    "\n",
    "For our purpose we will assume we already have this information available as we attempt to predict the weather on a given day."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "71eqGzF8RWv8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import tensorflow_probability as tfp  # We are using a different module from tensorflow this time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ],
   "execution_count": 60,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cenp3DTieuEf",
    "colab_type": "text"
   },
   "source": [
    "Here we coded a model for the following:\n",
    "\n",
    "1. Cold days are encoded by a 0 and hot days are encoded by a 1.\n",
    "2. The first day in our sequence has an 80% chance of being cold.\n",
    "3. A cold day has a 30% chance of being followed by a hot day.\n",
    "4. A hot day has a 20% chance of being followed by a cold day.\n",
    "5. On each day the temperature is normally distributed with mean and standard deviation 0 and 5 on a cold day and mean and standard deviation 15 and 10 on a hot day.\n",
    "\n",
    "**Standard deviation** gives us the range of values above or below the mean\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "M5wwoVekEHm5",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#Here we create probability of distribution model\n",
    "tfd = tfp.distributions  # making a shortcut for later on\n",
    "#bracket probability representation - [Cold Day, Hot Day]\n",
    "initial_distribution = tfd.Categorical(probs=[0.8, 0.2])  # Refer to point 2 above\n",
    "transition_distribution = tfd.Categorical(probs=[[0.7, 0.3],\n",
    "                                                 [0.2, 0.8]])  # refer to points 3 and 4 above\n",
    "observation_distribution = tfd.Normal(loc=[0., 15.], scale=[5., 10.])  # insert standard deviation. Refer to point 5 above\n",
    "#loc=[mean] scale=[standard deviation]\n",
    "# the loc argument represents the mean and the scale is the standard devitation"
   ],
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-6zMGrr5Rcye",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#Here we use hidden Markov model\n",
    "model = tfd.HiddenMarkovModel(\n",
    "    initial_distribution=initial_distribution,\n",
    "    transition_distribution=transition_distribution,\n",
    "    observation_distribution=observation_distribution,\n",
    "    num_steps=7)"
   ],
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDcskrMNTVel",
    "colab_type": "text"
   },
   "source": [
    "The number of steps represents the number of days that we would like to predict information for. In this case we've chosen 7, an entire week.\n",
    "\n",
    "To get the expected temperatures on each day we can do the following."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X0zs4E-qTVGu",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "mean = model.mean() #Partially defined tensor - This calculates the probablity so that we can run our probability distribution model\n",
    "\n",
    "# due to the way TensorFlow works on a lower level we need to evaluate part of the graph\n",
    "# from within a session to see the value of this tensor\n",
    "\n",
    "# in the new version of tensorflow we need to use tf.compat.v1.Session() rather than just tf.Session()\n",
    "with tf.compat.v1.Session() as sess:  \n",
    "  print(mean.numpy())"
   ],
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.9999998 6.        7.500001  8.25      8.625001  8.812501  8.906251 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 07:49:39.443356: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-11 07:49:39.443374: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4z2zK5Sk3Wu",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The model and session combines gives the temperature on 7 days (the reason we input a 7 in the steps portion of the model\n",
    "\n",
    "Note: temperature is in celsius\n",
    "\n",
    "- [**Day 1:** 2.9999998 | **Day 2:** 5.9999995 | **Day 3:** 7.4999995 | **Day 4:** 8.25 | **Day 5:** 8.625001 | **Day 6:** 8.812501 | **Day 7:** 8.90625  ]"
   ]
  }
 ]
}